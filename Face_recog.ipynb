{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ffd5be-f3b8-4abf-84c7-e97866983e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\modza\\Documents\\instagram\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\modza\\Documents\\instagram\\env\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\modza\\Documents\\instagram\\env\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "detector = MTCNN()\n",
    "#Load a videopip TensorFlow\n",
    "video_capture = cv2.VideoCapture(0)\n",
    " \n",
    "while (True):\n",
    "    ret, frame = video_capture.read()\n",
    "    frame = cv2.resize(frame, (600, 400))\n",
    "    boxes = detector.detect_faces(frame)\n",
    "    if boxes:\n",
    " \n",
    "        box = boxes[0]['box']\n",
    "        conf = boxes[0]['confidence']\n",
    "        x, y, w, h = box[0], box[1], box[2], box[3]\n",
    " \n",
    "        if conf > 0.5:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "817c514f-86e6-4124-a93b-cd7d35d1bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget  -O detector.tflite -q https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5817f1-5f94-4200-bc3f-c46503c49936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -q -O detector.tflite https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "601578fb-6941-4821-bb7b-bc67a7ff18f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download the file.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"detector.tflite\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"File 'detector.tflite' downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download the file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2ff95-9767-422f-9d0f-17ee917a0c40",
   "metadata": {},
   "source": [
    "# Facial Landmark recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97087daf-fd8d-4f97-ba41-29796edf80eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\modza\\Documents\\instagram\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import cv2\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646163b6-f6cb-4bb3-a0d9-7ce312a5c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    " \n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1106fbed-1c60-4731-9571-c3615be7d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "holistic = mp_holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    smooth_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c797d5-8631-463b-aa5a-94673364b9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mediapipe.python.solutions.holistic.Holistic at 0x21aca9982d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58af6e7-9f08-41ec-8073-56adcf81fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0445a36f-5775-44b4-abd3-642a76f1d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initializing current time and precious time for calculating the FPS\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "while capture.isOpened():\n",
    "\t# capture frame by frame\n",
    "\tret, frame = capture.read()\n",
    "\n",
    "\t# resizing the frame for better view\n",
    "\tframe = cv2.resize(frame, (800, 600))\n",
    "\n",
    "\t# Converting the from BGR to RGB\n",
    "\timage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\t# Making predictions using holistic model\n",
    "\t# To improve performance, optionally mark the image as not writeable to\n",
    "\t# pass by reference.\n",
    "\timage.flags.writeable = False\n",
    "\tresults = holistic_model.process(image)\n",
    "\timage.flags.writeable = True\n",
    "\n",
    "\t# Converting back the RGB image to BGR\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\t# Drawing the Facial Landmarks\n",
    "\tmp_drawing.draw_landmarks(\n",
    "\timage,\n",
    "\tresults.face_landmarks,\n",
    "\tmp_holistic.FACEMESH_CONTOURS,\n",
    "\tmp_drawing.DrawingSpec(\n",
    "\t\tcolor=(255,0,255),\n",
    "\t\tthickness=1,\n",
    "\t\tcircle_radius=1\n",
    "\t),\n",
    "\tmp_drawing.DrawingSpec(\n",
    "\t\tcolor=(0,255,255),\n",
    "\t\tthickness=1,\n",
    "\t\tcircle_radius=1\n",
    "\t)\n",
    "\t)\n",
    "\n",
    "\t# Drawing Right hand Land Marks\n",
    "\tmp_drawing.draw_landmarks(\n",
    "\timage, \n",
    "\tresults.right_hand_landmarks, \n",
    "\tmp_holistic.HAND_CONNECTIONS\n",
    "\t)\n",
    "\n",
    "\t# Drawing Left hand Land Marks\n",
    "\tmp_drawing.draw_landmarks(\n",
    "\timage, \n",
    "\tresults.left_hand_landmarks, \n",
    "\tmp_holistic.HAND_CONNECTIONS\n",
    "\t)\n",
    "\t\n",
    "\t# Calculating the FPS\n",
    "\tcurrentTime = time.time()\n",
    "\tfps = 1 / (currentTime-previousTime)\n",
    "\tpreviousTime = currentTime\n",
    "\t\n",
    "\t# Displaying FPS on the image\n",
    "\tcv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "\t# Display the resulting image\n",
    "\tcv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "\n",
    "\t# Enter key 'q' to break the loop\n",
    "\tif cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21767eda-9db8-4c8a-bb9b-209095febdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\modza\\Documents\\instagram\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'frozenset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m face_width \u001b[38;5;241m=\u001b[39m (rightmost_x \u001b[38;5;241m-\u001b[39m leftmost_x) \u001b[38;5;241m*\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate interpupillary distance (distance between eyes)\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m left_eye_x \u001b[38;5;241m=\u001b[39m landmarks[mp_holistic\u001b[38;5;241m.\u001b[39mFACEMESH_CONTOURS[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mx\n\u001b[0;32m     47\u001b[0m right_eye_x \u001b[38;5;241m=\u001b[39m landmarks[mp_holistic\u001b[38;5;241m.\u001b[39mFACEMESH_CONTOURS[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]\u001b[38;5;241m.\u001b[39mx\n\u001b[0;32m     48\u001b[0m interpupillary_distance \u001b[38;5;241m=\u001b[39m (right_eye_x \u001b[38;5;241m-\u001b[39m left_eye_x) \u001b[38;5;241m*\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'frozenset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "while capture.isOpened():\n",
    "    # Capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Resize the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Converting the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(rgb_frame)\n",
    "\n",
    "        # Converting back the RGB frame to BGR\n",
    "        rgb_frame.flags.writeable = True\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Check if a face is detected\n",
    "        if results.face_landmarks:\n",
    "            # Extract facial landmarks\n",
    "            landmarks = results.face_landmarks.landmark\n",
    "\n",
    "            # Calculate face width (distance between outermost points)\n",
    "            leftmost_x = min(landmarks, key=lambda lm: lm.x).x\n",
    "            rightmost_x = max(landmarks, key=lambda lm: lm.x).x\n",
    "            face_width = (rightmost_x - leftmost_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate interpupillary distance (distance between eyes)\n",
    "            left_eye_x = landmarks[mp_holistic.FACEMESH_CONTOURS[0][0]].x\n",
    "            right_eye_x = landmarks[mp_holistic.FACEMESH_CONTOURS[0][-1]].x\n",
    "            interpupillary_distance = (right_eye_x - left_eye_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate nose bridge height (vertical distance between nose tip and eyebrows)\n",
    "            nose_tip_y = landmarks[mp_holistic.FACEMESH_CONTOURS[3][-1]].y\n",
    "            eyebrows_y = (landmarks[mp_holistic.FACEMESH_CONTOURS[0][0]].y + landmarks[mp_holistic.FACEMESH_CONTOURS[0][-1]].y) / 2\n",
    "            nose_bridge_height = (nose_tip_y - eyebrows_y) * frame.shape[0]\n",
    "\n",
    "            # Display the calculated measurements\n",
    "            cv2.putText(bgr_frame, f\"Face Width: {face_width:.2f}\", (10, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Interpupillary Distance: {interpupillary_distance:.2f}\", (10, 140), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Nose Bridge Height: {nose_bridge_height:.2f}\", (10, 180), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "\n",
    "        # Calculating the FPS\n",
    "        currentTime = time.time()\n",
    "        fps = 1 / (currentTime - previousTime)\n",
    "        previousTime = currentTime\n",
    "\n",
    "        # Displaying FPS on the image\n",
    "        cv2.putText(bgr_frame, f\"{int(fps)} FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Facial Geometry\", bgr_frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879fef7f-2880-44b2-aa54-e283de199b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\modza\\Documents\\instagram\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "# Manually define the face contour points (indices)\n",
    "face_contour_indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 179, 148, 152, 377, 400, 378, 379, 365, 397, 288, 361, 323, 454, 356, 389, 251, 284, 332, 297, 338]\n",
    "\n",
    "while capture.isOpened():\n",
    "    # Capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Resize the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Converting the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(rgb_frame)\n",
    "\n",
    "        # Converting back the RGB frame to BGR\n",
    "        rgb_frame.flags.writeable = True\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Check if a face is detected\n",
    "        if results.face_landmarks:\n",
    "            # Extract facial landmarks\n",
    "            landmarks = results.face_landmarks.landmark\n",
    "\n",
    "            # Calculate face width (distance between outermost points)\n",
    "            leftmost_x = min(landmarks, key=lambda lm: lm.x).x\n",
    "            rightmost_x = max(landmarks, key=lambda lm: lm.x).x\n",
    "            face_width = (rightmost_x - leftmost_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate interpupillary distance (distance between eyes)\n",
    "            left_eye_x = landmarks[159].x  # Left eye landmark index\n",
    "            right_eye_x = landmarks[386].x  # Right eye landmark index\n",
    "            interpupillary_distance = (right_eye_x - left_eye_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate nose bridge height (vertical distance between nose tip and eyebrows)\n",
    "            nose_tip_y = landmarks[9].y  # Nose tip landmark index\n",
    "            eyebrows_y = (landmarks[152].y + landmarks[148].y) / 2  # Eyebrow landmarks indices\n",
    "            nose_bridge_height = (nose_tip_y - eyebrows_y) * frame.shape[0]\n",
    "\n",
    "            # Display the calculated measurements\n",
    "            cv2.putText(bgr_frame, f\"Face Width: {face_width:.2f}\", (10, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Interpupillary Distance: {interpupillary_distance:.2f}\", (10, 140), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Nose Bridge Height: {nose_bridge_height:.2f}\", (10, 180), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "\n",
    "        # Calculating the FPS\n",
    "        currentTime = time.time()\n",
    "        fps = 1 / (currentTime - previousTime)\n",
    "        previousTime = currentTime\n",
    "\n",
    "        # Displaying FPS on the image\n",
    "        cv2.putText(bgr_frame, f\"{int(fps)} FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Facial Geometry\", bgr_frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5f40ec-86d9-43e3-bd4b-852aeffedf6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.python.solutions.holistic' has no attribute 'FACE_CONNECTIONS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 67\u001b[0m\n\u001b[0;32m     61\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(bgr_frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNose Bridge Height: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnose_bridge_height\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m180\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[38;5;241m0.8\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Draw facial landmarks (mesh points)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     mp_drawing\u001b[38;5;241m.\u001b[39mdraw_landmarks(\n\u001b[0;32m     65\u001b[0m         bgr_frame,\n\u001b[0;32m     66\u001b[0m         results\u001b[38;5;241m.\u001b[39mface_landmarks,\n\u001b[1;32m---> 67\u001b[0m         mp_holistic\u001b[38;5;241m.\u001b[39mFACE_CONNECTIONS,\n\u001b[0;32m     68\u001b[0m         landmark_drawing_spec\u001b[38;5;241m=\u001b[39mmp_drawing\u001b[38;5;241m.\u001b[39mDrawingSpec(color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, circle_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     69\u001b[0m         connection_drawing_spec\u001b[38;5;241m=\u001b[39mmp_drawing\u001b[38;5;241m.\u001b[39mDrawingSpec(color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, circle_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Calculating the FPS\u001b[39;00m\n\u001b[0;32m     73\u001b[0m currentTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mediapipe.python.solutions.holistic' has no attribute 'FACE_CONNECTIONS'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "# Manually define the face contour points (indices)\n",
    "face_contour_indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 179, 148, 152, 377, 400, 378, 379, 365, 397, 288, 361, 323, 454, 356, 389, 251, 284, 332, 297, 338]\n",
    "\n",
    "while capture.isOpened():\n",
    "    # Capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Resize the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Converting the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(rgb_frame)\n",
    "\n",
    "        # Converting back the RGB frame to BGR\n",
    "        rgb_frame.flags.writeable = True\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Check if a face is detected\n",
    "        if results.face_landmarks:\n",
    "            # Extract facial landmarks\n",
    "            landmarks = results.face_landmarks.landmark\n",
    "\n",
    "            # Calculate face width (distance between outermost points)\n",
    "            leftmost_x = min(landmarks, key=lambda lm: lm.x).x\n",
    "            rightmost_x = max(landmarks, key=lambda lm: lm.x).x\n",
    "            face_width = (rightmost_x - leftmost_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate interpupillary distance (distance between eyes)\n",
    "            left_eye_x = landmarks[159].x  # Left eye landmark index\n",
    "            right_eye_x = landmarks[386].x  # Right eye landmark index\n",
    "            interpupillary_distance = (right_eye_x - left_eye_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate nose bridge height (vertical distance between nose tip and eyebrows)\n",
    "            nose_tip_y = landmarks[9].y  # Nose tip landmark index\n",
    "            eyebrows_y = (landmarks[152].y + landmarks[148].y) / 2  # Eyebrow landmarks indices\n",
    "            nose_bridge_height = (nose_tip_y - eyebrows_y) * frame.shape[0]\n",
    "\n",
    "            # Display the calculated measurements\n",
    "            cv2.putText(bgr_frame, f\"Face Width: {face_width:.2f}\", (10, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Interpupillary Distance: {interpupillary_distance:.2f}\", (10, 140), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Nose Bridge Height: {nose_bridge_height:.2f}\", (10, 180), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "\n",
    "            # Draw facial landmarks (mesh points)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                bgr_frame,\n",
    "                results.face_landmarks,\n",
    "                mp_holistic.FACE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=1, circle_radius=1),\n",
    "            )\n",
    "\n",
    "        # Calculating the FPS\n",
    "        currentTime = time.time()\n",
    "        fps = 1 / (currentTime - previousTime)\n",
    "        previousTime = currentTime\n",
    "\n",
    "        # Displaying FPS on the image\n",
    "        cv2.putText(bgr_frame, f\"{int(fps)} FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Facial Geometry\", bgr_frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97698d83-0b66-4f27-90f1-810cf72779d4",
   "metadata": {},
   "source": [
    "# Facial Geometry extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35658fbf-cd18-4886-aff4-7fe9bb69e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "# Manually define the face contour points (indices)\n",
    "face_contour_indices = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 179, 148, 152, 377, 400, 378, 379, 365, 397, 288, 361, 323, 454, 356, 389, 251, 284, 332, 297, 338]\n",
    "\n",
    "while capture.isOpened():\n",
    "    # Capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Resize the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Converting the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(rgb_frame)\n",
    "\n",
    "        # Converting back the RGB frame to BGR\n",
    "        rgb_frame.flags.writeable = True\n",
    "        bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Check if a face is detected\n",
    "        if results.face_landmarks:\n",
    "            # Extract facial landmarks\n",
    "            landmarks = results.face_landmarks.landmark\n",
    "\n",
    "            # Calculate face width (distance between outermost points)\n",
    "            leftmost_x = min(landmarks, key=lambda lm: lm.x).x\n",
    "            rightmost_x = max(landmarks, key=lambda lm: lm.x).x\n",
    "            face_width = (rightmost_x - leftmost_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate interpupillary distance (distance between eyes)\n",
    "            left_eye_x = landmarks[159].x  # Left eye landmark index\n",
    "            right_eye_x = landmarks[386].x  # Right eye landmark index\n",
    "            interpupillary_distance = (right_eye_x - left_eye_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate nose bridge height (vertical distance between nose tip and eyebrows)\n",
    "            nose_tip_y = landmarks[9].y  # Nose tip landmark index\n",
    "            eyebrows_y = (landmarks[152].y + landmarks[148].y) / 2  # Eyebrow landmarks indices\n",
    "            nose_bridge_height = (nose_tip_y - eyebrows_y) * frame.shape[0]\n",
    "\n",
    "            # Display the calculated measurements\n",
    "            cv2.putText(bgr_frame, f\"Face Width: {face_width:.2f}\", (10, 100), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Interpupillary Distance: {interpupillary_distance:.2f}\", (10, 140), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "            cv2.putText(bgr_frame, f\"Nose Bridge Height: {nose_bridge_height:.2f}\", (10, 180), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 0, 255), 2)\n",
    "\n",
    "            # Draw facial landmarks (mesh points)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                bgr_frame,\n",
    "                results.face_landmarks,\n",
    "                mp_holistic.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=1, circle_radius=1),\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=1, circle_radius=1),\n",
    "            )\n",
    "\n",
    "        # Calculating the FPS\n",
    "        currentTime = time.time()\n",
    "        fps = 1 / (currentTime - previousTime)\n",
    "        previousTime = currentTime\n",
    "\n",
    "        # Displaying FPS on the image\n",
    "        cv2.putText(bgr_frame, f\"{int(fps)} FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Facial Geometry\", bgr_frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2dbf60-fb20-4459-9980-009704554a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql\n",
      "  Downloading mysql-0.0.3-py3-none-any.whl (1.2 kB)\n",
      "Collecting mysqlclient (from mysql)\n",
      "  Downloading mysqlclient-2.2.1-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Downloading mysqlclient-2.2.1-cp311-cp311-win_amd64.whl (202 kB)\n",
      "   ---------------------------------------- 0.0/202.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/202.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/202.8 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 92.2/202.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 202.8/202.8 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mysqlclient, mysql\n",
      "Successfully installed mysql-0.0.3 mysqlclient-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6716fbb-b1d8-4c14-baf8-2d237891d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-8.2.0-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting protobuf<=4.21.12,>=4.21.1 (from mysql-connector-python)\n",
      "  Downloading protobuf-4.21.12-cp310-abi3-win_amd64.whl (527 kB)\n",
      "     ---------------------------------------- 0.0/527.0 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/527.0 kB ? eta -:--:--\n",
      "     -- ---------------------------------- 41.0/527.0 kB 487.6 kB/s eta 0:00:01\n",
      "     ---------------------------- --------- 389.1/527.0 kB 3.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 527.0/527.0 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading mysql_connector_python-8.2.0-cp311-cp311-win_amd64.whl (14.2 MB)\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.8/14.2 MB 50.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.2/14.2 MB 2.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.5/14.2 MB 3.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.7/14.2 MB 3.0 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.8/14.2 MB 2.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/14.2 MB 2.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.9/14.2 MB 2.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.0/14.2 MB 2.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.1/14.2 MB 2.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.2/14.2 MB 2.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.4/14.2 MB 2.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.5/14.2 MB 2.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.7/14.2 MB 2.8 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.9/14.2 MB 2.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.1/14.2 MB 3.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.4/14.2 MB 3.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.6/14.2 MB 3.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.9/14.2 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.2/14.2 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.6/14.2 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.9/14.2 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.3/14.2 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.7/14.2 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.1/14.2 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.5/14.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.0/14.2 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.4/14.2 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.7/14.2 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.0/14.2 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.2/14.2 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.2 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.6/14.2 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.8/14.2 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.0/14.2 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.2/14.2 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.5/14.2 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.8/14.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.0/14.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.3/14.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.6/14.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.0/14.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.3/14.2 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.7/14.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.1/14.2 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.4/14.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.7/14.2 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.0/14.2 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.2/14.2 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.4/14.2 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.6/14.2 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.7/14.2 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.8/14.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/14.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.0/14.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.2/14.2 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, mysql-connector-python\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed mysql-connector-python-8.2.0 protobuf-4.21.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.9 requires protobuf<4,>=3.11, but you have protobuf 4.21.12 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741399a-e205-4046-88a9-78a52526e977",
   "metadata": {},
   "source": [
    "import mysql.connector\n",
    "\n",
    "def get_connection():\n",
    "    mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    database=\"stocks\",\n",
    "    password=\"Thermodynamics@1\"\n",
    "    )\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "    return mycursor, mydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3578af7-144b-484f-b731-cba5318ce20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Thermodynamics@1\",\n",
    "    database=\"snapchat\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81fb7a38-2867-4768-a261-02a8685ebe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import mysql.connector\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Initialize camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "# Connect to your MySQL database (replace placeholders with your database details)\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Thermodynamics@1\",\n",
    "    database=\"snapchat\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define a function to insert measurements into the database\n",
    "def insert_measurement(face_width, interpupillary_distance, nose_bridge_height):\n",
    "    insert_query = \"INSERT INTO face (face_width, interpupillary_distance, nose_bridge_height) VALUES (%s, %s, %s)\"\n",
    "    values = (face_width, interpupillary_distance, nose_bridge_height)\n",
    "    cursor.execute(insert_query, values)\n",
    "    conn.commit()\n",
    "\n",
    "while capture.isOpened():\n",
    "    # Capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Resize the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Converting the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(rgb_frame)\n",
    "\n",
    "        # Check if a face is detected\n",
    "        if results.face_landmarks:\n",
    "            # Extract facial landmarks\n",
    "            landmarks = results.face_landmarks.landmark\n",
    "\n",
    "            # Calculate face width (distance between outermost points)\n",
    "            leftmost_x = min(landmarks, key=lambda lm: lm.x).x\n",
    "            rightmost_x = max(landmarks, key=lambda lm: lm.x).x\n",
    "            face_width = (rightmost_x - leftmost_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate interpupillary distance (distance between eyes)\n",
    "            left_eye_x = landmarks[159].x  # Left eye landmark index\n",
    "            right_eye_x = landmarks[386].x  # Right eye landmark index\n",
    "            interpupillary_distance = (right_eye_x - left_eye_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate nose bridge height (vertical distance between nose tip and eyebrows)\n",
    "            nose_tip_y = landmarks[9].y  # Nose tip landmark index\n",
    "            eyebrows_y = (landmarks[152].y + landmarks[148].y) / 2  # Eyebrow landmarks indices\n",
    "            nose_bridge_height = (nose_tip_y - eyebrows_y) * frame.shape[0]\n",
    "\n",
    "            # Insert the calculated measurements into the database\n",
    "            insert_measurement(face_width, interpupillary_distance, nose_bridge_height)\n",
    "\n",
    "        # Display the resulting image (you can add this part if needed)\n",
    "        cv2.imshow(\"Facial Geometry\", frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close the database connection and release the capture when done\n",
    "conn.close()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9966260-2251-4ccd-896b-a32dded1cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import mysql.connector\n",
    "import time\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Initialize camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "# Connect to your MySQL database (replace placeholders with your database details)\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Thermodynamics@1\",\n",
    "    database=\"snapchat\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define a function to insert measurements into the database\n",
    "def insert_measurement(face_width, interpupillary_distance, nose_bridge_height):\n",
    "    insert_query = \"INSERT INTO face (face_width, interpupillary_distance, nose_bridge_height) VALUES (%s, %s, %s)\"\n",
    "    values = (face_width, interpupillary_distance, nose_bridge_height)\n",
    "    cursor.execute(insert_query, values)\n",
    "    conn.commit()\n",
    "\n",
    "while capture.isOpened():\n",
    "    # Capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Resize the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Converting the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(rgb_frame)\n",
    "\n",
    "        # Check if a face is detected\n",
    "        if results.face_landmarks:\n",
    "            # Extract facial landmarks\n",
    "            landmarks = results.face_landmarks.landmark\n",
    "\n",
    "            # Calculate face width (distance between outermost points)\n",
    "            leftmost_x = min(landmarks, key=lambda lm: lm.x).x\n",
    "            rightmost_x = max(landmarks, key=lambda lm: lm.x).x\n",
    "            face_width = (rightmost_x - leftmost_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate interpupillary distance (distance between eyes)\n",
    "            left_eye_x = landmarks[159].x  # Left eye landmark index\n",
    "            right_eye_x = landmarks[386].x  # Right eye landmark index\n",
    "            interpupillary_distance = (right_eye_x - left_eye_x) * frame.shape[1]\n",
    "\n",
    "            # Calculate nose bridge height (vertical distance between nose tip and eyebrows)\n",
    "            nose_tip_y = landmarks[9].y  # Nose tip landmark index\n",
    "            eyebrows_y = (landmarks[152].y + landmarks[148].y) / 2  # Eyebrow landmarks indices\n",
    "            nose_bridge_height = (nose_tip_y - eyebrows_y) * frame.shape[0]\n",
    "\n",
    "            # Insert the calculated measurements into the database\n",
    "            insert_measurement(face_width, interpupillary_distance, nose_bridge_height)\n",
    "\n",
    "            # Display facial landmark coordinates\n",
    "            for idx, landmark in enumerate(landmarks):\n",
    "                x, y = int(landmark.x * frame.shape[1]), int(landmark.y * frame.shape[0])\n",
    "                cv2.putText(frame, f\"LM{idx}: ({x}, {y})\", (10, 30 + idx * 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "            # Display geometry calculations\n",
    "            cv2.putText(frame, f\"Face Width: {face_width:.2f}\", (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Interpupillary Distance: {interpupillary_distance:.2f}\", (10, 430), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Nose Bridge Height: {nose_bridge_height:.2f}\", (10, 460), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Facial Geometry\", frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close the database connection and release the capture when done\n",
    "conn.close()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db32c9ad-f7ba-4fd4-80a2-30782b092c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"Truncate table face\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442ae1ab-3888-4462-8335-6cd5ee98b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Thermodynamics@1\",\n",
    "    database=\"snapchat\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d18595-64f1-4862-a304-69b50c4b526e",
   "metadata": {},
   "source": [
    "cursor.execute(\"select * from face\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747b8f0-25f8-4371-8370-5541a0f31b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
